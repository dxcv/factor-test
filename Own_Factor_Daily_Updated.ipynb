{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#!/Tsan/bin/python\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Libraries To Use\n",
    "from __future__ import division \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "from sklearn import linear_model\n",
    "from datetime import datetime,time,date\n",
    "import matplotlib.pyplot as plt\n",
    "import theano.tensor as T\n",
    "from theano import function\n",
    "import seaborn as sns\n",
    "from theano.tensor.shared_randomstreams import RandomStreams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import My own library for factor testing\n",
    "from SingleFactorTest import factorFilterFunctions as ff\n",
    "#from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "path = ff.data_path # path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "filenameFCAP = 'LZ_GPA_VAL_A_FCAP.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------- Global Functions to def---------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# top functions to def\n",
    "def simpleNormalize(narrowedData):\n",
    "    dataWinsorized = narrowedData.copy()\n",
    "    dataWinsorizedTrans = dataWinsorized.T\n",
    "    MAD = 1.483*np.abs(dataWinsorizedTrans-dataWinsorizedTrans.median(skipna=True))\n",
    "    return ((dataWinsorizedTrans - dataWinsorizedTrans.mean(axis=0, skipna=True))/dataWinsorizedTrans.std(axis=0, skipna=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# top function\n",
    "def neutralizeFactor(normalizedFactorDF, normalizedLFCAPDF, datelist):\n",
    "    factorNeutralized = pd.DataFrame(index=normalizedFactorDF.index, columns=normalizedFactorDF.columns, data=None, dtype = float)\n",
    "    for date in datelist:\n",
    "        LFCAPIndice = normalizedLFCAPDF.loc[date].dropna()\n",
    "        factorIndice = normalizedFactorDF.loc[date].dropna()\n",
    "        intersectionStocks = list(set(LFCAPIndice.index) & set(factorIndice.index))\n",
    "        #dummy_Matrix = pd.get_dummies(IndustryDF.loc[date]).T.iloc[:-1]\n",
    "        #dummy_Matrix = dummy_Matrix[intersectionStocks].append(LFCAPIndice.loc[intersectionStocks])\n",
    "        try:\n",
    "            result = sm. OLS(factorIndice.loc[intersectionStocks].T, LFCAPIndice.loc[intersectionStocks].T).fit()\n",
    "            factorNeutralized.loc[date][intersectionStocks] = result.resid\n",
    "        except:\n",
    "            factorNeutralized.loc[date] = np.NaN\n",
    "    return factorNeutralized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------- Function Section End ---------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Data prepared for Neuralization\n",
    "FCAP1 = np.log10(pd.read_csv(path+filenameFCAP,infer_datetime_format=True,parse_dates=[0],index_col=0))\n",
    "NormalizedFCAP = simpleNormalize(FCAP1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------- Calculate Forward Adjusted Price ---------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# the necessary files\n",
    "filenameAdjustFactor='LZ_GPA_CMFTR_CUM_FACTOR.csv'\n",
    "filenamePirce='LZ_GPA_QUOTE_TCLOSE.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# first is to calculate forward adjusted pice\n",
    "def calAdjustedPrice():\n",
    "    # Adjusted factor\n",
    "    AdjFacBackward=pd.read_csv(path+filenameAdjustFactor,infer_datetime_format=True,parse_dates=[0],index_col=0)\n",
    "    #AdjFacBackward=AdjFacBackward[:]\n",
    "\n",
    "    #PriceData to Adjust\n",
    "    PriceToAdj=pd.read_csv(path+filenamePirce,infer_datetime_format=True,parse_dates=[0],index_col=0)\n",
    "    #PriceToAdj=PriceToAdj[:]\n",
    "\n",
    "    #Calculate\n",
    "    AdjFacforward = AdjFacBackward / AdjFacBackward.max()\n",
    "    adjustedPrice = (AdjFacforward*PriceToAdj).round(5)\n",
    "    #adjustedPrice.index.name = 'LZ_GPA_DERI_AdjustedPriceForward_20-d' \n",
    "    adjustedPrice.index.name = 'Own_Factor_AdjustedPriceForward-1d'\n",
    "    print adjustedPrice.index.name \n",
    "    adjustedPrice.to_csv(path+'Own_Factor_AdjustedPriceForward-1d.csv',na_rep='NaN',date_format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (9009,) (3,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-164-e4fba3e39da0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcalAdjustedPrice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-163-2eb985f2bd1e>\u001b[0m in \u001b[0;36mcalAdjustedPrice\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[1;31m#Calculate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mAdjFacforward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdjFacBackward\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mAdjFacBackward\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0madjustedPrice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mAdjFacforward\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mPriceToAdj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[1;31m#adjustedPrice.index.name = 'LZ_GPA_DERI_AdjustedPriceForward_20-d'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\python27\\lib\\site-packages\\pandas\\core\\ops.pyc\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, other, axis, level, fill_value)\u001b[0m\n\u001b[1;32m   1228\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_combine_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1230\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_combine_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1231\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfill_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\python27\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_combine_series\u001b[0;34m(self, other, func, fill_value, axis, level)\u001b[0m\n\u001b[1;32m   3583\u001b[0m                                                    fill_value=fill_value)\n\u001b[1;32m   3584\u001b[0m         return self._combine_series_infer(other, func, level=level,\n\u001b[0;32m-> 3585\u001b[0;31m                                           fill_value=fill_value)\n\u001b[0m\u001b[1;32m   3586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3587\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_combine_series_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\python27\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_combine_series_infer\u001b[0;34m(self, other, func, level, fill_value)\u001b[0m\n\u001b[1;32m   3595\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3596\u001b[0m         return self._combine_match_columns(other, func, level=level,\n\u001b[0;32m-> 3597\u001b[0;31m                                            fill_value=fill_value)\n\u001b[0m\u001b[1;32m   3598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3599\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_combine_match_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\python27\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_combine_match_columns\u001b[0;34m(self, other, func, level, fill_value)\u001b[0m\n\u001b[1;32m   3615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3616\u001b[0m         new_data = left._data.eval(func=func, other=right,\n\u001b[0;32m-> 3617\u001b[0;31m                                    axes=[left.columns, self.index])\n\u001b[0m\u001b[1;32m   3618\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\python27\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   3160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3161\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3162\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'eval'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3164\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mquantile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\python27\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m   3054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3055\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mgr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3056\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3057\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3058\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\python27\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, func, other, raise_on_error, try_cast, mgr)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m         \u001b[1;31m# if we have an invalid shape/broadcast error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\python27\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(other)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m             \u001b[1;31m# mask if needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\python27\\lib\\site-packages\\pandas\\core\\ops.pyc\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0myrav\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m                 \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnotnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxrav\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mnotnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myrav\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m                 \u001b[0mxrav\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxrav\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (9009,) (3,) "
     ]
    }
   ],
   "source": [
    "calAdjustedPrice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "000005.SZ        9.393567\n",
       "600601.SH     5974.691786\n",
       "600602.SH      513.680061\n",
       "600651.SH     5905.618552\n",
       "600652.SH     5505.536186\n",
       "600653.SH    10055.640083\n",
       "600654.SH     1506.963701\n",
       "600656.SH       17.770853\n",
       "000004.SZ        4.063862\n",
       "000002.SZ      133.886691\n",
       "000001.SZ      107.166489\n",
       "000009.SZ        7.347011\n",
       "000003.SZ             NaN\n",
       "600603.SH       77.283530\n",
       "000012.SZ       17.618287\n",
       "000016.SZ       20.695610\n",
       "600604.SH       26.234874\n",
       "600605.SH       35.010198\n",
       "600606.SH      115.985090\n",
       "600607.SH       78.096562\n",
       "600608.SH       99.475227\n",
       "000011.SZ        3.491401\n",
       "000017.SZ        2.682738\n",
       "000007.SZ        5.521192\n",
       "000006.SZ       32.921011\n",
       "000020.SZ        1.751825\n",
       "000013.SZ             NaN\n",
       "000008.SZ       22.050885\n",
       "000014.SZ        5.427468\n",
       "000018.SZ        6.632775\n",
       "                 ...     \n",
       "603096.SH        1.004437\n",
       "002866.SZ        1.060259\n",
       "300514.SZ        1.099885\n",
       "603920.SH        1.004407\n",
       "002867.SZ        1.061434\n",
       "603787.SH        1.100132\n",
       "603320.SH        1.100180\n",
       "002868.SZ        1.007265\n",
       "300647.SZ        1.000000\n",
       "300650.SZ        1.000000\n",
       "603505.SH        1.100524\n",
       "603501.SH        1.100123\n",
       "300643.SZ        1.000000\n",
       "300649.SZ        1.000000\n",
       "603985.SH        1.100070\n",
       "300651.SZ        1.000000\n",
       "603229.SH        1.099853\n",
       "603728.SH        1.100153\n",
       "603896.SH        1.100109\n",
       "603926.SH        1.100141\n",
       "002871.SZ        1.000000\n",
       "603086.SH        1.099857\n",
       "603113.SH        1.100094\n",
       "603180.SH        1.100000\n",
       "002869.SZ             NaN\n",
       "002870.SZ             NaN\n",
       "601952.SH        1.439914\n",
       "300652.SZ             NaN\n",
       "300653.SZ             NaN\n",
       "603488.SH             NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3323L,)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdjFacBackward.max().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------- Calculate ILLQ Factor(5-days average) ---------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "filenameClose = 'LZ_GPA_QUOTE_TCLOSE.csv'\n",
    "filenameOpen = 'LZ_GPA_QUOTE_TOPEN.csv'\n",
    "filenameVolume = 'LZ_GPA_QUOTE_TVOLUME.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calcILLQ(): # rolling_window is set as 5 days\n",
    "    openPrice = pd.read_csv(path+filenameOpen,infer_datetime_format=True,parse_dates=[0],index_col=0)\n",
    "    closePrice = pd.read_csv(path+filenameClose,infer_datetime_format=True,parse_dates=[0],index_col=0)\n",
    "    volume = pd.read_csv(path+filenameVolume,infer_datetime_format=True,parse_dates=[0],index_col=0)\n",
    "    if openPrice.shape != closePrice.shape:\n",
    "        print openPrice.shape, closePrice.shape\n",
    "        print 'data shape is not equal!'\n",
    "    else:\n",
    "        newdf = np.abs((closePrice - openPrice)/openPrice)/volume\n",
    "        newdf = newdf.rolling(min_periods=5,window=5,center=False).mean()\n",
    "        newdf.index.name = 'Own_Factor_ILLQ-1d'\n",
    "        newdf.to_csv(path+'Own_Factor_ILLQ-1d.csv',na_rep='NaN',date_format='%Y%m%d')\n",
    "        return newdf       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#filenameILLQ = 'Own_Factor_ILLQ-1d.csv'\n",
    "#openPrice = pd.read_csv(path+filenameILLQ,infer_datetime_format=True,parse_dates=[0],index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ILLQdf = calcILLQ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TO nuetralize DDA20\n",
    "NormalizedILLQ = simpleNormalize(ILLQdf)\n",
    "neutralizedILLQ = neutralizeFactor(NormalizedILLQ, NormalizedFCAP, NormalizedILLQ.index)\n",
    "neutralizedILLQ.index.name = 'Own_Factor_ADJ_ILLQ_1D'\n",
    "neutralizedILLQ.to_csv(path+neutralizedILLQ.index.name+'.csv',na_rep='NaN',date_format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------- Calculate FCAP Adjusted Turnover Volume---------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------- ILLIQ End--------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# REMINDER: Code in this section can be used to neutralize any new factor! Use this to check some size-affected factor!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "filenameTURNOVER = 'LZ_GPA_QUOTE_TVOLUME.csv'\n",
    "filenameFCAP = 'LZ_GPA_VAL_A_FCAP.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "TURNOVER = pd.read_csv(path+filenameTURNOVER,infer_datetime_format=True,parse_dates=[0],index_col=0)\n",
    "FCAP1 = np.log10(pd.read_csv(path+filenameFCAP,infer_datetime_format=True,parse_dates=[0],index_col=0))\n",
    "\n",
    "TURNOVER= simpleNormalize(TURNOVER)\n",
    "\n",
    "FCAP1 = simpleNormalize(FCAP1 )\n",
    "\n",
    "datelist = FCAP1.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "adjustedTurnOver = neutralizeFactor(TURNOVER , FCAP1, datelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "adjustedTurnOver.index.name = 'Own_Factor_AdjustedTurnOver-1d'\n",
    "adjustedTurnOver.to_csv(path+'Own_Factor_AdjustedTurnOver-1d.csv',na_rep='NaN',date_format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------- Calculate FCAP Adjusted PB ---------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "filenamePB = 'LZ_GPA_VAL_PB.csv'\n",
    "filenameFCAP = 'LZ_GPA_VAL_A_FCAP.csv'\n",
    "PB = pd.read_csv(path+filenamePB ,infer_datetime_format=True,parse_dates=[0],index_col=0)\n",
    "PB = simpleNormalize(PB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "adjustedPB = neutralizeFactor(PB , FCAP1, datelist)\n",
    "adjustedPB.index.name = 'Own_Factor_AdjustedPB-1d'\n",
    "adjustedPB.to_csv(path+'Own_Factor_AdjustedPB-1d.csv',na_rep='NaN',date_format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pb1 = pd.read_csv(path+'Own_Factor_AdjustedPB-1d.csv',infer_datetime_format=True,parse_dates=[0],index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pb1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------- Calculate  x-days return volatility  ---------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "filenameAdjPrice =  'Own_Factor_AdjustedPriceForward-1d.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calReturnVol(period): # 90days maybe good\n",
    "    AdjPrice = pd.read_csv(path+filenameAdjPrice,infer_datetime_format=True,parse_dates=[0],index_col=0)\n",
    "    returnDF = AdjPrice.pct_change()\n",
    "    newdf = returnDF.rolling(min_periods=20,window=period,center=False).std()\n",
    "    newdf.index.name = 'Own_Factor_Volatility_%dd' % period\n",
    "    newdf.to_csv(path+'Own_Factor_Volatility_%dd.csv' % period,na_rep='NaN',date_format='%Y%m%d')\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "calReturnVol(90).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------- Calculate  x-days return Skew ---------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calReturnSkew(period):\n",
    "    AdjPrice = pd.read_csv(path+filenameAdjPrice,infer_datetime_format=True,parse_dates=[0],index_col=0)\n",
    "    returnDF = AdjPrice.pct_change()\n",
    "    newdf = returnDF.rolling(min_periods=120,window=period,center=False).skew()\n",
    "    newdf.index.name = 'Own_Factor_Return_Skew_%dD' % period\n",
    "    newdf.to_csv(path+newdf.index.name+'.csv',na_rep='NaN',date_format='%Y%m%d')\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calReturnSkew(250).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------- Calculate  x-days return above 20 days MA  ---------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calAbove20MA(period):\n",
    "    AdjPrice = pd.read_csv(path+filenameAdjPrice,infer_datetime_format=True,parse_dates=[0],index_col=0)\n",
    "    newdf = AdjPrice - AdjPrice.rolling(min_periods=20,window=period,center=False).mean()\n",
    "    newdf = newdf.rolling(min_periods=20,window=period,center=False).mean()\n",
    "    newdf.index.name = 'Own_Factor_Above20MA_%dd' % period\n",
    "    newdf.to_csv(path+'Own_Factor_Above20MA_%dd.csv' % period,na_rep='NaN',date_format='%Y%m%d')\n",
    "    return newdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "calAbove20MA(20).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------- Calculate  ARoon  ---------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "AdjPrice = pd.read_csv(path+filenameAdjPrice,infer_datetime_format=True,parse_dates=[0],index_col=0).iloc[-1000:]\n",
    "adcopy = AdjPrice.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "adcopy.iloc[:,2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calAroon(data, l=20):\n",
    "    datacopy = data.copy()\n",
    "    for i in range(l,len(datacopy)):\n",
    "        s = datacopy.iloc[i-l:i]\n",
    "        #print s\n",
    "        try:\n",
    "            data.iloc[i] = pd.Timedelta(s.idxmax().date() - s.idxmin().date()).days/l\n",
    "        except:\n",
    "            data.iloc[i] = np.NaN\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#aroonData = adcopy.iloc[:,:10].apply(calAroon,l=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------- Aroon End  ---------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------- Calculate  daily deal Amount(yuan)   ---------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "filenameTVolume = 'LZ_GPA_QUOTE_TVOLUME.csv' # 成交量\n",
    "filenameAdjPrice =  'Own_Factor_AdjustedPriceForward-1d.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calcDDA():\n",
    "    turnOver = pd.read_csv(path+filenameTVolume,infer_datetime_format=True,parse_dates=[0],index_col=0)\n",
    "    closePrice = pd.read_csv(path+filenameAdjPrice,infer_datetime_format=True,parse_dates=[0],index_col=0)\n",
    "    #volume = pd.read_csv(path+filenameVolume,infer_datetime_format=True,parse_dates=[0],index_col=0)\n",
    "    if turnOver.shape != closePrice.shape:\n",
    "        print turnOver.shape, closePrice.shape\n",
    "        print 'data shape is not equal!'\n",
    "    else:\n",
    "        newdf = turnOver * closePrice\n",
    "        #newdf = newdf.rolling(min_periods=5,window=5,center=False).mean()\n",
    "        newdf.index.name = 'Own_Factor_DDA-1d'\n",
    "        newdf.to_csv(path+'Own_Factor_DDA-1d.csv',na_rep='NaN',date_format='%Y%m%d')\n",
    "        return newdf           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "calcDDA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "filenameDDA = 'Own_Factor_DDA-1d.csv'\n",
    "DDAdf = pd.read_csv(path+filenameDDA,infer_datetime_format=True,parse_dates=[0],index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def DDAaverage(period):\n",
    "    DDAmean = DDAdf.rolling(min_periods=20,window=period,center=False).mean()\n",
    "    DDAmean.index.name = 'Own_Factor_DDA-%dd' % period\n",
    "    DDAmean.to_csv(path+'Own_Factor_DDA-%dd.csv' % period, na_rep='NaN',date_format='%Y%m%d')\n",
    "    return DDAmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "DDA20df= DDAaverage(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TO nuetralize DDA20\n",
    "NormalizedDDA20 = simpleNormalize(DDA20df)\n",
    "neutralizedDDA20 = neutralizeFactor(NormalizedDDA20, NormalizedFCAP, NormalizedDDA20.index)\n",
    "neutralizedDDA20.index.name = 'Own_Factor_ADJ_DDA_20D'\n",
    "neutralizedDDA20.to_csv(path+neutralizedDDA20.index.name+'.csv',na_rep='NaN',date_format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------- Calculate  annual idiosyncratic volatility(daily updated)   ---------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cal_factor_return(factor, stkreturn, factorname):\n",
    "    '''\n",
    "    To cal the return of the factor by group method( best(1/3) - worst(1/3))\n",
    "    Output: Dataframe, the factor Return with only one value column\n",
    "    Input:\n",
    "    factor: Dataframe, the factor Value df, Note that shift(1) has been used before this function is used\n",
    "    stkreturn:  Dataframe, the return of all stock in the market. No shift needed.\n",
    "    factorname:  String, the name of the factor!\n",
    "    '''\n",
    "    factorReturn = pd.DataFrame(index=factor.index[1:-1], columns=[factorname], data =None , dtype =float)\n",
    "    for date in factorReturn.index:\n",
    "        factorSlice = factor.loc[date].dropna()\n",
    "        stkreturnSlice = stkreturn.loc[date].dropna()\n",
    "        intersection = list(set(factorSlice.index) & set(stkreturnSlice.index))\n",
    "        factorSlice = factorSlice.loc[intersection]\n",
    "        stkreturnSlice = stkreturnSlice.loc[intersection]\n",
    "        \n",
    "        q_min = factorSlice.quantile(0.33)\n",
    "        q_max = factorSlice.quantile(0.66)\n",
    "        q_min_univ = factorSlice[factorSlice<=q_min]\n",
    "        q_max_univ = factorSlice[factorSlice>=q_max]\n",
    "        q_min_return = (q_min_univ * stkreturnSlice.loc[q_min_univ.index]).sum() / q_min_univ.sum()\n",
    "        q_max_return = (q_max_univ * stkreturnSlice.loc[q_max_univ.index]).sum() / q_max_univ.sum()\n",
    "        #print q_min_return\n",
    "        factorReturn.loc[date] = q_min_return - q_max_return\n",
    "    return factorReturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "startTime =  datetime.strptime('20100101', '%Y%m%d')\n",
    "endTime = datetime.strptime('20170328', '%Y%m%d')\n",
    "filenameAdjPrice =  'Own_Factor_AdjustedPriceForward-1d.csv'\n",
    "filenameFCAP = 'LZ_GPA_VAL_A_FCAP.csv'\n",
    "filenamePB='LZ_GPA_VAL_PB.csv'  # 市净率\n",
    "filenameBENCH = 'LZ_GPA_INDXQUOTE_CLOSE.csv'\n",
    "ZZ500Index = '000905.SH' #   ZZ500 index code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pricedf = pd.read_csv(path+filenameAdjPrice,infer_datetime_format=True,parse_dates=[0],index_col=0).loc[startTime:endTime]\n",
    "FCAPdf  = pd.read_csv(path+filenameFCAP,infer_datetime_format=True,parse_dates=[0],index_col=0).loc[startTime:endTime]\n",
    "PBdf = pd.read_csv(path+filenamePB,infer_datetime_format=True,parse_dates=[0],index_col=0).loc[startTime:endTime]\n",
    "benchmarkdf = pd.read_csv(path+filenameBENCH,infer_datetime_format=True,parse_dates=[0],index_col=0)[ZZ500Index].loc[startTime:endTime].pct_change()\n",
    "returndf = pricedf.pct_change()\n",
    "FCAPdf = FCAPdf .shift(1)\n",
    "PBdf = PBdf.shift(1)\n",
    "FCAPdf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "SizeReturn = cal_factor_return(FCAPdf, returndf , 'Size_Return')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "SizeReturn.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "PBReturn = cal_factor_return(PBdf, returndf , 'PB_Return')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "PBReturn.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "benchmarkdf = benchmarkdf.loc[PBReturn.index[0]:PBReturn.index[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "benchmarkdf .isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "returndf = returndf.loc[PBReturn.index[0]:PBReturn.index[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "startOfMonthList, endOfMonthList = ff.getLastDayOfMonth(PBReturn.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(startOfMonthList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "len(endOfMonthList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "datetuple = list(zip(startOfMonthList,endOfMonthList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calIdoVol(returnDF , factorReturnList , datetuple ,torelance = 0.05):\n",
    "    '''\n",
    "    function to calculate to idiosyncratic volatility.\n",
    "    Output: Dataframe, The idiosyncratic volatility factor (same shape as ohter daily factor).\n",
    "    Input : \n",
    "    returnDF: Dataframe, the data of the return of all stocks.\n",
    "    factorReturn: List, the element is the factor-return dataframe. (Obtained by group-method so there is only one value \\\n",
    "    column(and one index column)\n",
    "    for each dataframe).Note that this df has been shift(1) to ensure that future data is not used!\n",
    "    datatuple: List, element is the tuple which is consisted of startTime and endTime. Usually zip by the startOfMonthList and endOfMonthList.\n",
    "    torelance: float, to filter the Nan Value.\n",
    "    '''\n",
    "    startdf = pd.DataFrame()\n",
    "    for i in datetuple:        \n",
    "        returnDFSlice = returnDF.loc[i[0]:i[1]]\n",
    "        tempdf= pd.DataFrame(index = returnDFSlice.index, columns = returnDFSlice.columns ,data = None ,dtype =float)\n",
    "        newReturnSlice = returnDFSlice.loc[:,returnDFSlice.isnull().sum() < returnDFSlice.shape[1] * torelance]\n",
    "        newReturnSlice = newReturnSlice.fillna(method = 'ffill').fillna(method = 'bfill')\n",
    "        filterList = newReturnSlice.columns.tolist()\n",
    "        mapfunction = map(lambda x: x.loc[i[0]:i[1]], factorReturnList)\n",
    "        totaldf = pd.concat(mapfunction, axis=1) \n",
    "        for stk in filterList:\n",
    "            result = sm.OLS(newReturnSlice[stk],totaldf).fit()\n",
    "            tempdf[stk].loc[i[0]:i[1]] = np.std(result.resid) * np.sqrt(242)\n",
    "        startdf = startdf.append(tempdf)\n",
    "    return startdf        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfList = [PBReturn,SizeReturn,benchmarkdf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dd = calIdoVol(returndf , dfList,datetuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dd.index.name = 'Own_FACTOR_Idiosyncratic_Volatility'\n",
    "dd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dd.to_csv(path+'Own_Factor_Idiosyncratic_Volatility.csv', na_rep='NaN',date_format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------- Calculate  annual idiosyncratic volatility(daily updated)   ---------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ddc =dd.tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "filenameIDIVOL = 'Own_Factor_Idiosyncratic_Volatility.csv'\n",
    "idio = pd.read_csv(path+filenameIDIVOL,infer_datetime_format=True,parse_dates=[0],index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "idio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def adj_boxplot(factorData):\n",
    "    '''To calculate  adjusted -boxplot winsorized data and then Normalize the outcome\n",
    "    Output: Dataframe, the winsorized and normalized data\n",
    "    Input: \n",
    "    factorData:Dataframe, raw data, can contain nan value\n",
    "    '''\n",
    "    copyData = factorData.copy()\n",
    "    for i in copyData.index:\n",
    "        temp = copyData.loc[i]\n",
    "        x = temp.dropna().values\n",
    "        if len(x) > 0:\n",
    "            mc = sm.stats.stattools.medcouple(x)\n",
    "            x.sort()\n",
    "            q1 = x[int(0.25*len(x))]\n",
    "            q3 = x[int(0.75*len(x))]\n",
    "            iqr = q3-q1\n",
    "            if mc >= 0:\n",
    "                l = q1-1.5*np.exp(-3.5*mc)*iqr\n",
    "                u = q3+1.5*np.exp(4*mc)*iqr\n",
    "            else:\n",
    "                l = q1-1.5*np.exp(-4*mc)*iqr\n",
    "                u = q3+1.5*np.exp(3.5*mc)*iqr\n",
    "            temp.loc[temp < l] = l\n",
    "            temp.loc[temp > u] = u\n",
    "            #factor_data.loc[i] = (temp-temp.mean())/temp.std()\n",
    "    Trans = copyData.T\n",
    "    return ((Trans  - Trans .mean(axis=0, skipna=True))/Trans .std(axis=0, skipna=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%mprun  addd = adj_boxplot(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%lprun -f adj_boxplot adj_boxplot(idio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------- Calculate  some random factor  ---------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "filenameAdjPrice =  'Own_Factor_AdjustedPriceForward-1d.csv'\n",
    "filenameVolume = 'LZ_GPA_QUOTE_TVOLUME.csv'\n",
    "closePrice = pd.read_csv(path+filenameAdjPrice,infer_datetime_format=True,parse_dates=[0],index_col=0)\n",
    "tradVol = pd.read_csv(path+filenameVolume,infer_datetime_format=True,parse_dates=[0],index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calrandfac(pricedf, factordf):\n",
    "    sgndf= np.sign(pricedf.pct_change())\n",
    "    tempo = factordf * sgndf\n",
    "    tempo = tempo.ewm(ignore_na=True, min_periods=5, halflife = 5).mean()\n",
    "    return tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "overheatVol = calrandfac(closePrice, tradVol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "overheatVol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "overheatVol.index.name = 'OVER_HEAT_VOL'\n",
    "overheatVol.to_csv(path+'Over_Heat_Volume.csv', na_rep='NaN',date_format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------- Calculate  skewness  ---------------------------------- #\n",
    "filenameAdjPrice =  'Own_Factor_AdjustedPriceForward-1d.csv'\n",
    "closePrice = pd.read_csv(path+filenameAdjPrice,infer_datetime_format=True,parse_dates=[0],index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# calculate N-days skewness of the price\n",
    "def calSkewness(pricedf,period):\n",
    "    df = pricedf.rolling(min_periods=250,window=period,center=False).skew()\n",
    "    df.index.name =  'Own_Factor_Skewness_%dd' % period\n",
    "    df.to_csv(path+'Own_Factor_Skewness_%dd.csv' % period,na_rep='NaN',date_format='%Y%m%d')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "priceSkewness = calSkewness(closePrice,250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------- Calculate  TurnOver Rate Volatility ---------------------------------- #\n",
    "filenameTOR= 'LZ_GPA_VAL_TURN.csv'\n",
    "turnoverdf =  pd.read_csv(path+filenameTOR,infer_datetime_format=True,parse_dates=[0],index_col=0)\n",
    "FCAP1 = np.log10(pd.read_csv(path+filenameFCAP,infer_datetime_format=True,parse_dates=[0],index_col=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calToRvol(period):\n",
    "    newdf = turnoverdf.rolling(min_periods=20,window=period,center=False).std()\n",
    "    newdf.index.name = 'Own_Factor_Turnover_Volatility_%dD' % period\n",
    "    newdf.to_csv(path+'Own_Factor_Turnover_Volatility_%dD.csv' % period,na_rep='NaN',date_format='%Y%m%d')\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "newsdf = calToRvol(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "newsdf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "NormalizedTOV = simpleNormalize(newsdf )\n",
    "NormalizedFCAP = simpleNormalize(FCAP1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "neutralizedTOV = neutralizeFactor(NormalizedTOV, NormalizedFCAP, NormalizedTOV.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "neutralizedTOV.index.name = 'Own_Factor_ADJ_Turnover_Volatility_20D'\n",
    "neutralizedTOV.to_csv(path+neutralizedTOV.index.name+'.csv',na_rep='NaN',date_format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calToRVolD(period):\n",
    "    newdf = turnoverdf.rolling(min_periods=20,window=period,center=False).mean()\n",
    "    newdf1 = turnoverdf.rolling(min_periods=500,window=500,center=False).mean()\n",
    "    newdf = newdf / newdf1 -1\n",
    "    newdf.index.name = 'Own_Factor_Turnover_Volatility_deviation_%dD' % period\n",
    "    newdf.to_csv(path+'Own_Factor_Turnover_Volatility_deviation_%dD.csv' % period,na_rep='NaN',date_format='%Y%m%d')\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df2 = calToRVolD(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df2 .tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "NormalizedTOVD = simpleNormalize(df2)\n",
    "neutralizedTOVD = neutralizeFactor(NormalizedTOVD, NormalizedFCAP, NormalizedTOVD.index)\n",
    "neutralizedTOVD.index.name = 'Own_Factor_ADJ_Turnover_Volatility_Deviation_20D'\n",
    "neutralizedTOVD.to_csv(path+neutralizedTOVD.index.name+'.csv',na_rep='NaN',date_format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "neutralizedTOVD .tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------- Calculate  adjusted Own factor  ILLQ  ---------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
